{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e4ccba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import functools\n",
    "\n",
    "import numpy\n",
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "import scipy.special\n",
    "import scipy.optimize\n",
    "\n",
    "from discohisto import (\n",
    "    fit_normal,\n",
    "    fit_cabinetry,\n",
    "    fit_cabinetry_post,\n",
    "    fit_linspace,\n",
    "    fit_mcmc_mix,\n",
    "    fit_mcmc_tfp_ham,\n",
    "    region,\n",
    "    limit,\n",
    "    stats,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4179e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCHES_PATH = \"searches/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f366b6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.cache\n",
    "def load_searches():\n",
    "    searches = []\n",
    "    for item in os.scandir(SEARCHES_PATH):\n",
    "        if not item.is_dir():\n",
    "            continue\n",
    "        searches.append(item.name)\n",
    "        \n",
    "    return sorted(searches)\n",
    "\n",
    "\n",
    "def load_reported(search):\n",
    "    path = os.path.join(SEARCHES_PATH, search, \"reported.json\")\n",
    "    with open(path) as file_:\n",
    "        reported = json.load(file_)\n",
    "    return reported\n",
    "\n",
    "\n",
    "def _get_n_region(reg):\n",
    "    sr_name = reg.signal_region_name\n",
    "    observations = reg.workspace\n",
    "\n",
    "    for obs in reg.workspace[\"observations\"]:\n",
    "        if obs[\"name\"] == sr_name:\n",
    "            return obs[\"data\"][0]\n",
    "\n",
    "    raise ValueError(sr_name)\n",
    "\n",
    "\n",
    "def _load_mcmc_limits(path, *, suffix):\n",
    "    mcmc_types = [\"mix\", \"tfp_ham\"]\n",
    "    lim = None\n",
    "    for mcmc_type in mcmc_types:\n",
    "        suffix_i = \"_mcmc_%s_%s\" % (mcmc_type, suffix)\n",
    "        try:\n",
    "            lim = limit.LimitScan.load(path, suffix=suffix_i)\n",
    "        except FileNotFoundError:\n",
    "            ...\n",
    "    assert lim is not None\n",
    "    return lim\n",
    "\n",
    "\n",
    "def _load_limit(limit_dir, suffix):\n",
    "    lim = limit.LimitScan.load(limit_dir, suffix=suffix)\n",
    "    assert lim.levels[6:8] == [-2, -3], lim.levels[6:8]\n",
    "    return lim\n",
    "\n",
    "\n",
    "def _limit_logl(lim):\n",
    "    return numpy.log(numpy.mean(lim.integral_zero))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1e31b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_frame():\n",
    "    searches = load_searches()\n",
    "    \n",
    "    # frame entries\n",
    "    search_ = []\n",
    "    region_ = []\n",
    "    reported_n = []\n",
    "    reported_bkg = []\n",
    "    reported_bkg_hi = []\n",
    "    reported_bkg_lo = []\n",
    "    reported_s95obs = []\n",
    "    reported_s95exp = []\n",
    "    reported_s95exp_hi = []\n",
    "    reported_s95exp_lo = []\n",
    "    \n",
    "    region_n = []\n",
    "    \n",
    "    fit_cabinetry_bkg = []\n",
    "    fit_cabinetry_err = []\n",
    "    fit_cabinetry_post_bkg = []\n",
    "    fit_cabinetry_post_err = []\n",
    "    \n",
    "    limit_cabinetry_obs_2 = []\n",
    "    limit_cabinetry_obs_3 = []\n",
    "    limit_cabinetry_log_like = []\n",
    "    \n",
    "    limit_cabinetry_post_obs_2 = []\n",
    "    limit_cabinetry_post_obs_3 = []\n",
    "    \n",
    "    limit_normal_obs_2 = []\n",
    "    limit_normal_obs_3 = []\n",
    "    limit_normal_log_like = []\n",
    "    \n",
    "    limit_normal_log_obs_2 = []\n",
    "    limit_normal_log_obs_3 = []\n",
    "    limit_normal_log_log_like = []\n",
    "    \n",
    "    limit_delta_obs_2 = []\n",
    "    limit_delta_obs_3 = []\n",
    "    limit_delta_log_like = []\n",
    "    \n",
    "    limit_linspace_obs_2 = []\n",
    "    limit_linspace_obs_3 = []\n",
    "    limit_linspace_log_like = []\n",
    "    \n",
    "    limit_mcmc_obs_2 = []\n",
    "    limit_mcmc_obs_3 = []\n",
    "    limit_mcmc_log_like = []\n",
    "    \n",
    "    for search in searches:\n",
    "        reported = load_reported(search)\n",
    "        for region_name in reported:\n",
    "            search_.append(search)\n",
    "            region_.append(region_name)\n",
    "            \n",
    "            # reported\n",
    "            reported_reg = reported[region_name]\n",
    "            \n",
    "            n_observed = reported_reg[\"n\"]\n",
    "            reported_n.append(n_observed)\n",
    "            reported_bkg.append(reported_reg[\"bkg\"])\n",
    "            reported_bkg_hi.append(reported_reg[\"bkg_hi\"])\n",
    "            reported_bkg_lo.append(reported_reg[\"bkg_lo\"])\n",
    "            reported_s95obs.append(reported_reg[\"s95obs\"])\n",
    "            reported_s95exp.append(reported_reg[\"s95exp\"])\n",
    "            reported_s95exp_hi.append(reported_reg[\"s95exp_hi\"])\n",
    "            reported_s95exp_lo.append(reported_reg[\"s95exp_lo\"])\n",
    "            \n",
    "            # region\n",
    "            region_dir = os.path.join(SEARCHES_PATH, search, region_name)\n",
    "            region_i = region.Region.load(region_dir)\n",
    "            region_n.append(_get_n_region(region_i))\n",
    "            \n",
    "            # standard fits\n",
    "            fit_dir = os.path.join(region_dir, \"fit\")\n",
    "            \n",
    "            fit = fit_cabinetry.FitCabinetry.load(fit_dir)\n",
    "            fit_cabinetry_bkg.append(fit.yield_pre)\n",
    "            fit_cabinetry_err.append(fit.error_pre)\n",
    "            \n",
    "            fit = fit_cabinetry_post.FitCabinetryPost.load(fit_dir)\n",
    "            fit_cabinetry_post_bkg.append(fit.yield_post)\n",
    "            fit_cabinetry_post_err.append(fit.error_post)\n",
    "            \n",
    "            fit = fit_normal.FitNormal.load(fit_dir)\n",
    "            mu_delta = fit.yield_linear\n",
    "            \n",
    "            # limits\n",
    "            limit_dir = os.path.join(fit_dir, \"limit\")\n",
    "            load_limit = functools.partial(_load_limit, limit_dir)\n",
    "            \n",
    "            lim = load_limit(\"_cabinetry_observed\")\n",
    "            limit_cabinetry_obs_2.append(lim.points[6][-1])\n",
    "            limit_cabinetry_obs_3.append(lim.points[7][-1])\n",
    "            limit_cabinetry_log_like.append(_limit_logl(lim))\n",
    "            \n",
    "            lim = load_limit(\"_cabinetry_post_observed\")\n",
    "            limit_cabinetry_post_obs_2.append(lim.points[6][-1])\n",
    "            limit_cabinetry_post_obs_3.append(lim.points[7][-1])\n",
    "            \n",
    "            lim = load_limit(\"_linspace_observed\")\n",
    "            limit_linspace_obs_2.append(lim.points[6][-1])\n",
    "            limit_linspace_obs_3.append(lim.points[7][-1])\n",
    "            limit_linspace_log_like.append(_limit_logl(lim))\n",
    "            \n",
    "            lim = load_limit(\"_normal_observed\")\n",
    "            limit_normal_obs_2.append(lim.points[6][-1])\n",
    "            limit_normal_obs_3.append(lim.points[7][-1])\n",
    "            limit_normal_log_like.append(_limit_logl(lim))\n",
    "            \n",
    "            lim = load_limit(\"_normal_log_observed\")\n",
    "            limit_normal_log_obs_2.append(lim.points[6][-1])\n",
    "            limit_normal_log_obs_3.append(lim.points[7][-1])\n",
    "            limit_normal_log_log_like.append(_limit_logl(lim))\n",
    "                        \n",
    "            lim = limit.LimitScanDelta.load(limit_dir, suffix=\"_observed\")\n",
    "            assert lim.levels[6:8] == [-2, -3], lim.levels[6:8]\n",
    "            limit_delta_obs_2.append(lim.points[6][-1])\n",
    "            limit_delta_obs_3.append(lim.points[7][-1])\n",
    "            limit_delta_log_like.append(stats.poisson_log_minus_max(n_observed, mu_delta))\n",
    "            \n",
    "            lim = _load_mcmc_limits(limit_dir, suffix=\"observed\")\n",
    "            assert lim.levels[6:8] == [-2, -3], lim.levels[6:8]\n",
    "            limit_mcmc_obs_2.append(lim.points[6][-1])\n",
    "            limit_mcmc_obs_3.append(lim.points[7][-1])\n",
    "            limit_mcmc_log_like.append(_limit_logl(lim))\n",
    "\n",
    "    out = dict(\n",
    "        # labels\n",
    "        search_=search_,\n",
    "        region_=region_,\n",
    "        # reported\n",
    "        reported_n=reported_n,\n",
    "        reported_bkg=reported_bkg,\n",
    "        reported_bkg_hi=reported_bkg_hi,\n",
    "        reported_bkg_lo=reported_bkg_lo,\n",
    "        reported_s95obs=reported_s95obs,\n",
    "        reported_s95exp=reported_s95exp,\n",
    "        reported_s95exp_hi=reported_s95exp_hi,\n",
    "        reported_s95exp_lo=reported_s95exp_lo,\n",
    "        region_n=region_n,\n",
    "        # fits\n",
    "        fit_cabinetry_bkg=fit_cabinetry_bkg,\n",
    "        fit_cabinetry_err=fit_cabinetry_err,\n",
    "        fit_cabinetry_post_bkg=fit_cabinetry_post_bkg,\n",
    "        fit_cabinetry_post_err=fit_cabinetry_post_err,\n",
    "        # limits\n",
    "        limit_cabinetry_obs_2=limit_cabinetry_obs_2,\n",
    "        limit_cabinetry_obs_3=limit_cabinetry_obs_3,\n",
    "        limit_cabinetry_log_like=limit_cabinetry_log_like,\n",
    "        limit_cabinetry_post_obs_2=limit_cabinetry_post_obs_2,\n",
    "        limit_cabinetry_post_obs_3=limit_cabinetry_post_obs_3,\n",
    "        limit_normal_obs_2=limit_normal_obs_2,\n",
    "        limit_normal_obs_3=limit_normal_obs_3,\n",
    "        limit_normal_log_like=limit_normal_log_like,\n",
    "        limit_normal_log_obs_2=limit_normal_log_obs_2,\n",
    "        limit_normal_log_obs_3=limit_normal_log_obs_3,\n",
    "        limit_normal_log_log_like=limit_normal_log_log_like,\n",
    "        limit_delta_obs_2=limit_delta_obs_2,\n",
    "        limit_delta_obs_3=limit_delta_obs_3,\n",
    "        limit_delta_log_like=limit_delta_log_like,\n",
    "        limit_linspace_obs_2=limit_linspace_obs_2,\n",
    "        limit_linspace_obs_3=limit_linspace_obs_3,\n",
    "        limit_linspace_log_like=limit_linspace_log_like,\n",
    "        limit_mcmc_obs_2=limit_mcmc_obs_2,\n",
    "        limit_mcmc_obs_3=limit_mcmc_obs_3,\n",
    "        limit_mcmc_log_like=limit_mcmc_log_like,\n",
    "    )\n",
    "    \n",
    "    return {key: numpy.array(value) for key, value in out.items()}\n",
    "        \n",
    "\n",
    "FRAME = load_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5b9dfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(numpy.array_equal(FRAME[\"reported_n\"], FRAME[\"region_n\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c74921",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(load_searches())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e00ddce",
   "metadata": {},
   "source": [
    "# Compare fitted backgrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9c05f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO error bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46671de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bkgs():\n",
    "    repored_bkg = FRAME[\"reported_bkg\"]\n",
    "    fit_cabinetry_bkg = FRAME[\"fit_cabinetry_bkg\"]\n",
    "\n",
    "    y = fit_cabinetry_bkg / repored_bkg\n",
    "    x = numpy.arange(len(y)) + 0.5\n",
    "    \n",
    "    pyplot.scatter(x, y, lw=0, s=2, marker=\",\")\n",
    "    \n",
    "    pyplot.ylim(0, 2)\n",
    "    pyplot.show()\n",
    "    \n",
    "plot_bkgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5793bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bkgs_post():\n",
    "    repored_bkg = FRAME[\"reported_bkg\"]\n",
    "    fit_cabinetry_bkg = FRAME[\"fit_cabinetry_post_bkg\"]\n",
    "\n",
    "    y = fit_cabinetry_bkg / repored_bkg\n",
    "    x = numpy.arange(len(y)) + 0.5\n",
    "    \n",
    "    pyplot.scatter(x, y, lw=0, s=2, marker=\",\")\n",
    "    \n",
    "    pyplot.ylim(0, 2)\n",
    "    pyplot.show()\n",
    "    \n",
    "plot_bkgs_post()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573da142",
   "metadata": {},
   "source": [
    "# Inspect mean log likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7f702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mean_log_likes():\n",
    "    name_to_mean_log_like = {\n",
    "        \"cabinetry\": FRAME[\"limit_cabinetry_log_like\"].mean(),\n",
    "        \"normal\": FRAME[\"limit_normal_log_like\"].mean(),\n",
    "        \"normal_log\": FRAME[\"limit_normal_log_log_like\"].mean(),\n",
    "        \"delta\": FRAME[\"limit_delta_log_like\"].mean(),\n",
    "        \"linspace\": FRAME[\"limit_linspace_log_like\"].mean(),\n",
    "        \"mcmc\": FRAME[\"limit_mcmc_log_like\"].mean(),\n",
    "    }\n",
    "    \n",
    "    ref = max(name_to_mean_log_like.values())\n",
    "    \n",
    "    for name, q in name_to_mean_log_like.items():\n",
    "        print(\"%15s %7.4f %7.4f\" % (name, q, q - ref))\n",
    "\n",
    "print_mean_log_likes()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed76d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_optimized_mixture():\n",
    "    name_to_mixture_part = {\n",
    "        \"cabinetry\": FRAME[\"limit_cabinetry_log_like\"],\n",
    "        \"normal_log\": FRAME[\"limit_normal_log_log_like\"],\n",
    "        \"linspace\": FRAME[\"limit_linspace_log_like\"],\n",
    "        \"mcmc\": FRAME[\"limit_mcmc_log_like\"],\n",
    "    }\n",
    "    \n",
    "    parts = numpy.stack(list(name_to_mixture_part.values())).T\n",
    "    \n",
    "    def mixture_mean_log_like(x):\n",
    "        log_weights = log_softmax(x)\n",
    "        return scipy.special.logsumexp(parts + log_weights, axis=1).mean()\n",
    "    \n",
    "    # logit coordinates have a shift freedom. Constrain it by setting x[-1]=0\n",
    "    def loss(x_start):\n",
    "        x = numpy.append(x_start, 0.0)\n",
    "        return -mixture_mean_log_like(x)\n",
    "    \n",
    "    result = scipy.optimize.minimize(\n",
    "        loss,\n",
    "        [0.0] * (len(name_to_mixture_part) - 1)\n",
    "    )\n",
    "    print(result)\n",
    "    \n",
    "    result_weights = numpy.exp(log_softmax(numpy.append(result.x, 0.0)))\n",
    "    print(\"weights\", result_weights)\n",
    "    \n",
    "    print(\"%15s %7.4f _______\" % (\"mixture\", -loss(result.x)))\n",
    "    x_p6_p4 = _safe_log([0.6, 0.4, 0])\n",
    "    # offset to wash out the appended zero\n",
    "    print(\"%15s %7.4f _______\" % (\".6, .4\", -loss(x_p6_p4 + 300)))\n",
    "    \n",
    "    # plot a scan\n",
    "    x = numpy.linspace(0, 1, 100)\n",
    "    y = []\n",
    "    for xi in x:\n",
    "        log_weights = _safe_log([xi, 1 - xi, 0])\n",
    "        # offset to wash out the appended zero\n",
    "        y.append(-loss(log_weights + 700))\n",
    "    pyplot.plot(x, y)\n",
    "    pyplot.show()\n",
    "    \n",
    "    \n",
    "def log_softmax(x):\n",
    "    # log(e^xi / sum e^xi)\n",
    "    s = x - x.max()\n",
    "    return s - numpy.log(numpy.exp(s).sum())\n",
    "\n",
    "\n",
    "def _safe_log(x):\n",
    "    x = numpy.asarray(x)\n",
    "    iszero = x == 0\n",
    "    return numpy.where(iszero, -numpy.inf, numpy.log(x + iszero))\n",
    "\n",
    "\n",
    "print_optimized_mixture()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f26f90f",
   "metadata": {},
   "source": [
    "# Compare observed limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278e89e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_limits(label):\n",
    "    reported_obs = FRAME[\"reported_s95obs\"]\n",
    "    label_obs_2 = FRAME[\"limit_%s_obs_2\" % label]\n",
    "    label_obs_3 = FRAME[\"limit_%s_obs_3\" % label]\n",
    "    \n",
    "    pyplot.scatter(reported_obs, label_obs_2, color=\"r\", lw=0, s=2, marker=\",\")\n",
    "    pyplot.scatter(reported_obs, label_obs_3, color=\"b\", lw=0, s=2, marker=\",\")\n",
    "    pyplot.plot([0, 400], [0, 400], \"k\", alpha=0.2)\n",
    "    \n",
    "    pyplot.yscale(\"log\")\n",
    "    pyplot.xscale(\"log\")\n",
    "    pyplot.xlim(1.5, 400)\n",
    "    pyplot.ylim(1.5, 400)\n",
    "    \n",
    "    pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9990e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_limits(\"cabinetry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2ec3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_limits(\"cabinetry_post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9497c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_limits(\"normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343891f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_limits(\"normal_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82a186b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_limits(\"delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfdcb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_limits(\"linspace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb29b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_limits(\"mcmc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fedb344",
   "metadata": {},
   "outputs": [],
   "source": [
    "2 / numpy.log(2), numpy.exp(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94512c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "3 / numpy.log(2), numpy.exp(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6b14e9",
   "metadata": {},
   "source": [
    "# Inspect anomalous differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ff703d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_anomalies(label):\n",
    "    search_ = FRAME[\"search_\"]\n",
    "    region_ = FRAME[\"region_\"]\n",
    "    reported_obs = FRAME[\"reported_s95obs\"]\n",
    "    label_obs_2 = FRAME[\"limit_%s_obs_2\" % label]\n",
    "    \n",
    "    parts = zip(search_, region_, reported_obs, label_obs_2)\n",
    "    \n",
    "    for search_i, region_i, reported_i, label_i in parts:\n",
    "        error = numpy.log(label_i / reported_i)\n",
    "        if not abs(error) > 0.3:\n",
    "            continue\n",
    "            \n",
    "        print(\n",
    "            \"%28s %28s %6.1f %6.1f %6.1f\" % \n",
    "            (search_i, region_i, reported_i, label_i, error)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7c95fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_anomalies(\"cabinetry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07c8ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_anomalies(\"linspace\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
